# ServiceMonitor para Prometheus
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: fenix-nfe-monitor
  namespace: fenix-nfe
  labels:
    app: nfe-api
    version: v1.0.0
spec:
  selector:
    matchLabels:
      app: nfe-api
  endpoints:
  - port: http
    path: /actuator/prometheus
    interval: 30s
    scrapeTimeout: 10s
    honorLabels: true
    metricRelabelings:
    - sourceLabels: [__name__]
      regex: 'jvm_.*'
      targetLabel: 'component'
      replacement: 'jvm'
    - sourceLabels: [__name__]
      regex: 'http_.*'
      targetLabel: 'component'
      replacement: 'http'
    - sourceLabels: [__name__]
      regex: 'nfe_.*'
      targetLabel: 'component'
      replacement: 'nfe'
---
# PrometheusRule para alertas
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: fenix-nfe-rules
  namespace: fenix-nfe
  labels:
    app: nfe-api
    version: v1.0.0
spec:
  groups:
  - name: nfe.rules
    rules:
    # Alertas de aplicação
    - alert: NFeAPIHighCPU
      expr: rate(container_cpu_usage_seconds_total{pod=~"nfe-api-.*"}[5m]) > 0.8
      for: 2m
      labels:
        severity: warning
        component: nfe-api
      annotations:
        summary: "NFe API high CPU usage"
        description: "Pod {{ $labels.pod }} has high CPU usage: {{ $value }}"
    
    - alert: NFeAPIHighMemory
      expr: container_memory_usage_bytes{pod=~"nfe-api-.*"} / container_spec_memory_limit_bytes > 0.8
      for: 2m
      labels:
        severity: warning
        component: nfe-api
      annotations:
        summary: "NFe API high memory usage"
        description: "Pod {{ $labels.pod }} has high memory usage: {{ $value }}"
    
    - alert: NFeAPIHighErrorRate
      expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
      for: 2m
      labels:
        severity: critical
        component: nfe-api
      annotations:
        summary: "NFe API high error rate"
        description: "Error rate is {{ $value }} errors per second"
    
    - alert: NFeAPIDown
      expr: up{job="fenix-nfe-api"} == 0
      for: 1m
      labels:
        severity: critical
        component: nfe-api
      annotations:
        summary: "NFe API is down"
        description: "NFe API has been down for more than 1 minute"
    
    - alert: NFeAPIHighResponseTime
      expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
      for: 5m
      labels:
        severity: warning
        component: nfe-api
      annotations:
        summary: "NFe API high response time"
        description: "95th percentile response time is {{ $value }}s"
    
    # Alertas de filas
    - alert: NFeQueueHighDepth
      expr: rabbitmq_queue_messages > 1000
      for: 5m
      labels:
        severity: warning
        component: rabbitmq
      annotations:
        summary: "NFe queue high depth"
        description: "Queue {{ $labels.queue }} has {{ $value }} messages"
    
    - alert: NFeQueueConsumerDown
      expr: rabbitmq_queue_consumers == 0
      for: 2m
      labels:
        severity: critical
        component: rabbitmq
      annotations:
        summary: "NFe queue consumer down"
        description: "Queue {{ $labels.queue }} has no consumers"
    
    # Alertas de banco de dados
    - alert: NFeDatabaseHighConnections
      expr: postgresql_database_connections > 80
      for: 5m
      labels:
        severity: warning
        component: postgresql
      annotations:
        summary: "NFe database high connections"
        description: "Database has {{ $value }} connections"
    
    - alert: NFeDatabaseSlowQueries
      expr: postgresql_query_duration_seconds > 5
      for: 2m
      labels:
        severity: warning
        component: postgresql
      annotations:
        summary: "NFe database slow queries"
        description: "Query {{ $labels.query }} took {{ $value }}s"
    
    # Alertas de cache
    - alert: NFeCacheHighMemory
      expr: redis_memory_used_bytes / redis_memory_max_bytes > 0.8
      for: 5m
      labels:
        severity: warning
        component: redis
      annotations:
        summary: "NFe cache high memory usage"
        description: "Redis memory usage is {{ $value }}%"
    
    - alert: NFeCacheDown
      expr: up{job="redis"} == 0
      for: 1m
      labels:
        severity: critical
        component: redis
      annotations:
        summary: "NFe cache is down"
        description: "Redis has been down for more than 1 minute"
---
# GrafanaDashboard
apiVersion: v1
kind: ConfigMap
metadata:
  name: fenix-nfe-dashboard
  namespace: fenix-nfe
  labels:
    app: nfe-api
    version: v1.0.0
data:
  dashboard.json: |
    {
      "dashboard": {
        "id": null,
        "title": "Fenix NFe API Dashboard",
        "tags": ["nfe", "api", "fenix"],
        "style": "dark",
        "timezone": "browser",
        "panels": [
          {
            "id": 1,
            "title": "NFe API Overview",
            "type": "stat",
            "targets": [
              {
                "expr": "up{job=\"fenix-nfe-api\"}",
                "legendFormat": "API Status"
              }
            ],
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
          },
          {
            "id": 2,
            "title": "Request Rate",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(http_requests_total[5m])",
                "legendFormat": "{{method}} {{endpoint}}"
              }
            ],
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
          },
          {
            "id": 3,
            "title": "Error Rate",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(http_requests_total{status=~\"5..\"}[5m])",
                "legendFormat": "5xx Errors"
              }
            ],
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8}
          },
          {
            "id": 4,
            "title": "Response Time",
            "type": "graph",
            "targets": [
              {
                "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
                "legendFormat": "95th percentile"
              }
            ],
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8}
          }
        ],
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "refresh": "30s"
      }
    }
---
# AlertManagerConfig
apiVersion: v1
kind: ConfigMap
metadata:
  name: fenix-nfe-alertmanager-config
  namespace: fenix-nfe
  labels:
    app: nfe-api
    version: v1.0.0
data:
  alertmanager.yml: |
    global:
      smtp_smarthost: 'localhost:587'
      smtp_from: 'alerts@fenix.com.br'
    
    route:
      group_by: ['alertname', 'component']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'default'
      routes:
      - match:
          severity: critical
        receiver: 'critical'
      - match:
          severity: warning
        receiver: 'warning'
    
    receivers:
    - name: 'default'
      email_configs:
      - to: 'admin@fenix.com.br'
        subject: '[Fenix NFe] {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          {{ end }}
    
    - name: 'critical'
      email_configs:
      - to: 'admin@fenix.com.br,oncall@fenix.com.br'
        subject: '[CRITICAL] Fenix NFe API Alert'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          {{ end }}
      webhook_configs:
      - url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        send_resolved: true
    
    - name: 'warning'
      email_configs:
      - to: 'admin@fenix.com.br'
        subject: '[WARNING] Fenix NFe API Alert'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          {{ end }}
